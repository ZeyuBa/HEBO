{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"},{"sourceId":7993471,"sourceType":"datasetVersion","datasetId":4705988}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":889.067827,"end_time":"2024-05-27T12:03:26.772027","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-27T11:48:37.7042","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_log_error\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\n\n# Load the data\ndf_train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv', index_col='id')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv', index_col='id')\n\n# Data Summary Statistics\nprint(\"Train Data Description:\")\nprint(df_train.describe())\n\nX = df_train.iloc[:, :-1]\ny = df_train.iloc[:, -1]\n\n# Convert 'sex' column to category\nX['Sex'] = X['Sex'].astype('category')\ndf_test['Sex'] = df_test['Sex'].astype('category')\n\n# Feature engineering\n\n# Step 1: Train the model\nmodel = LGBMRegressor(verbose=0, random_state=1)\nmodel.fit(X, y)\n\n# Step 2: Get feature importances\nimportances = model.feature_importances_\n\n# Create a DataFrame for better handling\nfeature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n\n# Step 3: Sort features by importance\nfeature_importances = feature_importances.sort_values(by='importance', ascending=True)\n\n# Print feature importances\nprint(\"\\nFeature Importances:\")\nprint(feature_importances)\n\nkf = KFold(n_splits=7, shuffle=True, random_state=1)\n\nbest_i = 0\nbest_score = 1\nfor i in range(3):\n    # Step 5: Select features that contribute to the top N% of total importance\n    selected_features = feature_importances[i:]\n    \n    # Extract the column names of the selected features\n    selected_columns = selected_features['feature']\n    \n    # Create the new DataFrame with only the selected features\n    X2 = X[selected_columns]\n    scores = cross_val_score(model, X2, y, scoring='neg_mean_squared_log_error', cv=kf, n_jobs=-1)\n    mean_score = -np.mean(scores)\n    RMLSE = np.sqrt(mean_score)\n    print(f\"RMSLE for removing {i} least important features: {RMLSE}\")\n    \n    if RMLSE < best_score:\n        best_score = RMLSE\n        best_i = i\n\nprint(f\"\\nBest RMLSE is {best_score} and {best_i} least important features were removed\\n\")\n# Remove extra features\nselected_features = feature_importances[best_i:]\nX = X[selected_features['feature']]\ndf_test = df_test[selected_features['feature']]\n\n\n# Modeling and Evaluation\n\n# CatBoost columns\ncat_columns = X.select_dtypes(include='category').columns.tolist()\n\n# List of models to evaluate\ncatboost_model = CatBoostRegressor(random_state=1, cat_features=cat_columns, verbose=False)\nlgbm_model = LGBMRegressor(verbose=-1, random_state=1)\nxgb_model = XGBRegressor(verbose=0, random_state=1, enable_categorical=True)\n\n# Fit the models on the training data\ncatboost_model.fit(X, y)\nlgbm_model.fit(X, y)\nxgb_model.fit(X, y)\n\n# Make predictions on the test set\ncatboost_preds = catboost_model.predict(df_test)\nlgbm_preds = lgbm_model.predict(df_test)\nxgb_preds = xgb_model.predict(df_test)\n\n# Averaging predictions\nfinal_preds = np.round((catboost_preds + lgbm_preds + xgb_preds) / 3).astype('int')\n\n# Submission\nsubmission = pd.DataFrame({'id': df_test.index, 'Rings': final_preds})\nsubmission.to_csv(\"submission.csv\", header=True, index=False)\n\n# Final output of the submission file\nprint(\"\\nSubmission Head:\")\nprint(submission.head())\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.644639,"end_time":"2024-05-27T11:48:46.787444","exception":false,"start_time":"2024-05-27T11:48:41.142805","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-16T23:23:06.844502Z","iopub.execute_input":"2024-06-16T23:23:06.844949Z","iopub.status.idle":"2024-06-16T23:23:58.175795Z","shell.execute_reply.started":"2024-06-16T23:23:06.844918Z","shell.execute_reply":"2024-06-16T23:23:58.174289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
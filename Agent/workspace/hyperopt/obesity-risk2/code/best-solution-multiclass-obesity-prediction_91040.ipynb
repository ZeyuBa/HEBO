{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"},{"sourceId":7009925,"sourceType":"datasetVersion","datasetId":4030196}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":427.449299,"end_time":"2024-02-19T03:28:08.116042","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-19T03:21:00.666743","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multiclass ObesityðŸ«„Prediction","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.016056,"end_time":"2024-02-19T03:21:03.44326","exception":false,"start_time":"2024-02-19T03:21:03.427204","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Multiclass Obesity Prediction\n\nMulticlass obesity prediction involves the development of predictive models to classify individuals into different obesity categories based on various features such as demographics, lifestyle factors, and health indicators. Obesity is a complex condition influenced by a multitude of factors, including genetics, diet, physical activity, and environmental factors.\n\n### Objective:\nThe primary objective of multiclass obesity prediction is to accurately classify individuals into different obesity categories, which typically include classes such as underweight, normal weight, overweight, and obese. This classification assists in identifying individuals at risk of obesity-related health issues and allows for targeted interventions and healthcare management strategies.\n\n### Data Collection and Features:\nData for multiclass obesity prediction typically include a wide range of features that may influence an individual's obesity status. These features can include demographic information (age, gender, ethnicity), lifestyle factors (dietary habits, physical activity levels), medical history (family history of obesity, presence of comorbidities), and physiological measurements (BMI, body fat percentage, blood pressure).\n\n### Model Development:\nMachine learning algorithms such as logistic regression, decision trees, random forests, support vector machines, and neural networks are commonly used for developing multiclass obesity prediction models. Feature selection, data preprocessing, and model evaluation techniques play crucial roles in building accurate and robust predictive models.\n\n### Model Evaluation:\nEvaluation of multiclass obesity prediction models involves assessing their performance in terms of classification accuracy, precision, recall, F1-score, and area under the receiver operating characteristic curve (ROC-AUC). Cross-validation techniques and confusion matrices are often employed to validate model performance and identify areas for improvement.\n\n### Applications:\nMulticlass obesity prediction models find applications in various domains, including healthcare, public health policy, and personalized medicine. They can assist healthcare providers in early identification of individuals at risk of obesity-related complications, guiding preventive measures, and designing tailored interventions to promote healthy lifestyles and weight management.\n\n### Challenges and Considerations:\nDeveloping accurate multiclass obesity prediction models faces several challenges, including data quality issues, class imbalance, feature selection, and model interpretability. Ethical considerations regarding data privacy and potential biases in predictive algorithms also need to be addressed to ensure fair and equitable healthcare outcomes for all individuals.\n\nIn summary, multiclass obesity prediction plays a vital role in addressing the global burden of obesity and its associated health risks by leveraging data-driven approaches to identify at-risk individuals and inform targeted interventions for prevention and management.","metadata":{}},{"cell_type":"code","source":"import os;\nimport tensorflow as tf\nimport random as rn\nos.listdir('/kaggle/input')\nos.environ['PYTHONHASHSEED'] = '51'\nrn.seed(89)\ntf.random.set_seed(40)","metadata":{"papermill":{"duration":13.398803,"end_time":"2024-02-19T03:21:16.918271","exception":false,"start_time":"2024-02-19T03:21:03.519468","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:21.406254Z","iopub.execute_input":"2024-02-19T17:20:21.406963Z","iopub.status.idle":"2024-02-19T17:20:34.637441Z","shell.execute_reply.started":"2024-02-19T17:20:21.40693Z","shell.execute_reply":"2024-02-19T17:20:34.636208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction\n<div style=\"font-size:120%\"> \n    <b>Goal:</b> We have to predict obesity risk in individuals.<br><br>\n    <b>Dataset Description:</b>\n</div>\n\n| Column | Full Form | Description| \n|---|---|---|\n| 'id'| id | Unique for each person(row)|\n|'Gender'| Gender| person's Gender|\n| 'Age' | Age| Dtype is float. Age is between 14 years to 61 years |\n|'Height'| Height | Height is in meter it's between 1.45m to 1.98m|\n| 'Weight' | Weight| Weight is between 39 to 165. I think it's in KG.|\n|'family_history_with_overweight'| family history <br> with overweight| yes or no question|\n| 'FAVC'| Frequent consumption <br> of high calorie food| it's yes or no question. i think question they asked is <br>do you consume high calorie food|\n|'FCVC'|  Frequency of <br>consumption of vegetables| Similar to FAVC. this is also `yes or no` question|\n|'NCP'| Number of main meals| dtype is float, NCP is between 1 & 4. I think it should be 1,2,3,4 <br>but our data is synthetic so it's taking float values|\n|'CAEC'| Consumption of <br>food between meals| takes 4 values `Sometimes`, `Frequently`, `no` & `Always` <br>|\n| 'SMOKE'| Smoke | yes or no question. i think the question is \"Do you smoke?\" |\n|'CH2O'| Consumption of <br>water daily| CH2O takes values between 1 & 3. again it's given as <br>float may be because of synthetic data. it's values should be 1,2 or 3|\n|'SCC'|  Calories consumption <br>monitoring| yes or no question|\n|'FAF'| Physical activity <br>frequency| FAF is between 0 to 3, 0 means no physical activity<br> and 3 means high workout. and again, in our data it's given as float|\n|'TUE'| Time using <br>technology devices| TUE is between 0 to 2. I think question will be \"How long you have <br>been using technology devices to track your health.\" in our data it's given as float |\n|'CALC'| Consumption of alcohol | Takes 3 values: `Sometimes`, `no`, `Frequently`|\n| 'MTRANS' | Transportation used| MTRANS takes 5 values `Public_Transportation`, `Automobile`, <br>`Walking`, `Motorbike`, & `Bike`|\n|'NObeyesdad'| TARGET | This is our target, takes 7 values, and in this comp. we have to give <br>the class name (Not the Probability, which is the case in most comp.)\n\n\n<div style=\"font-size:120%\"> \n    <b>NObeyesdad (Target Variable):</b>\n</div>\n\n* Insufficient_Weight : Less than 18.5\n* Normal_Weight       : 18.5 to 24.9\n* Obesity_Type_I      : 30.0 to 34.9\n* Obesity_Type_II     : 35.0 to 39.9\n* Obesity_Type_III   : Higher than 40\n* Overweight_Level_I, Overweight_Level_II takes values between 25 to 29\n\n","metadata":{"papermill":{"duration":0.016465,"end_time":"2024-02-19T03:21:16.950651","exception":false,"start_time":"2024-02-19T03:21:16.934186","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"papermill":{"duration":0.014926,"end_time":"2024-02-19T03:21:16.980877","exception":false,"start_time":"2024-02-19T03:21:16.965951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom category_encoders import OneHotEncoder, CatBoostEncoder, MEstimateEncoder\nfrom sklearn.model_selection import StratifiedGroupKFold\n\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import RidgeClassifier, LogisticRegression\n\nfrom sklearn import set_config\nimport os\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport optuna\nfrom sklearn.compose import ColumnTransformer\nfrom prettytable import PrettyTable\n\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.base import clone\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import accuracy_score\nimport optuna\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay","metadata":{"_kg_hide-input":true,"papermill":{"duration":5.962903,"end_time":"2024-02-19T03:21:22.958894","exception":false,"start_time":"2024-02-19T03:21:16.995991","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:34.639377Z","iopub.execute_input":"2024-02-19T17:20:34.640076Z","iopub.status.idle":"2024-02-19T17:20:40.474449Z","shell.execute_reply.started":"2024-02-19T17:20:34.640044Z","shell.execute_reply":"2024-02-19T17:20:40.473636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{"papermill":{"duration":0.015116,"end_time":"2024-02-19T03:21:22.991094","exception":false,"start_time":"2024-02-19T03:21:22.975978","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Set Prameters for Reproduciblity\npd.set_option(\"display.max_rows\",100)\nFILE_PATH = \"/kaggle/input/playground-series-s4e2/\"\nTARGET = \"NObeyesdad\"\nn_splits = 9\nRANDOM_SEED = 73","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.02256,"end_time":"2024-02-19T03:21:23.029467","exception":false,"start_time":"2024-02-19T03:21:23.006907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.475574Z","iopub.execute_input":"2024-02-19T17:20:40.475877Z","iopub.status.idle":"2024-02-19T17:20:40.481051Z","shell.execute_reply.started":"2024-02-19T17:20:40.475851Z","shell.execute_reply":"2024-02-19T17:20:40.479986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{"papermill":{"duration":0.015568,"end_time":"2024-02-19T03:21:23.06027","exception":false,"start_time":"2024-02-19T03:21:23.044702","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# load all data\ntrain = pd.read_csv(os.path.join(FILE_PATH, \"train.csv\"))\ntest = pd.read_csv(os.path.join(FILE_PATH, \"test.csv\"))\nsample_sub = pd.read_csv(os.path.join(FILE_PATH, \"sample_submission.csv\"))\ntrain_org = pd.read_csv(\"/kaggle/input/obesity-or-cvd-risk-classifyregressorcluster/ObesityDataSet.csv\")","metadata":{"papermill":{"duration":0.238174,"end_time":"2024-02-19T03:21:23.313862","exception":false,"start_time":"2024-02-19T03:21:23.075688","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.483207Z","iopub.execute_input":"2024-02-19T17:20:40.483541Z","iopub.status.idle":"2024-02-19T17:20:40.698824Z","shell.execute_reply.started":"2024-02-19T17:20:40.483516Z","shell.execute_reply":"2024-02-19T17:20:40.697928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore Data","metadata":{"papermill":{"duration":0.015262,"end_time":"2024-02-19T03:21:23.346877","exception":false,"start_time":"2024-02-19T03:21:23.331615","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def prettify_df(df):\n    table = PrettyTable()\n    table.field_names = df.columns\n\n    for row in df.values:\n        table.add_row(row)\n    print(table)\n","metadata":{"papermill":{"duration":0.022937,"end_time":"2024-02-19T03:21:23.385096","exception":false,"start_time":"2024-02-19T03:21:23.362159","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.700054Z","iopub.execute_input":"2024-02-19T17:20:40.700371Z","iopub.status.idle":"2024-02-19T17:20:40.70564Z","shell.execute_reply.started":"2024-02-19T17:20:40.700344Z","shell.execute_reply":"2024-02-19T17:20:40.704615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"papermill":{"duration":0.045145,"end_time":"2024-02-19T03:21:23.445417","exception":false,"start_time":"2024-02-19T03:21:23.400272","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.706802Z","iopub.execute_input":"2024-02-19T17:20:40.707113Z","iopub.status.idle":"2024-02-19T17:20:40.742431Z","shell.execute_reply.started":"2024-02-19T17:20:40.707086Z","shell.execute_reply":"2024-02-19T17:20:40.741489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Data\nprint(\"Train Data\")\nprint(f\"Total number of rows: {len(train)}\")\nprint(f\"Total number of columns: {train.shape[1]}\\n\")\n\n# Test Data\nprint(\"Test Data\")\nprint(f\"Total number of rows: {len(test)}\")\nprint(f\"Total number of columns:{test.shape[1]}\")","metadata":{"papermill":{"duration":0.02379,"end_time":"2024-02-19T03:21:23.484972","exception":false,"start_time":"2024-02-19T03:21:23.461182","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.743697Z","iopub.execute_input":"2024-02-19T17:20:40.744053Z","iopub.status.idle":"2024-02-19T17:20:40.750064Z","shell.execute_reply.started":"2024-02-19T17:20:40.744021Z","shell.execute_reply":"2024-02-19T17:20:40.749187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check null and unique count\n# FHWO: family_history_with_overweight\ntrain_copy = train.rename(columns={\"family_history_with_overweight\":\"FHWO\"})\ntmp = pd.DataFrame(index=train_copy.columns)\ntmp['count'] = train_copy.count()\ntmp['dtype'] = train_copy.dtypes\ntmp['nunique'] = train_copy.nunique()\ntmp['%nunique'] = (tmp['nunique']/len(train_copy))*100\ntmp['%null'] = (train_copy.isnull().sum()/len(train_copy))*100\ntmp['min'] = train_copy.min()\ntmp['max'] = train_copy.max()\ntmp\n\ntmp.reset_index(inplace=True)\ntmp = tmp.rename(columns = {\"index\":\"Column Name\"})\ntmp = tmp.round(3)\nprettify_df(tmp)\ndel tmp, train_copy","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.149086,"end_time":"2024-02-19T03:21:23.649786","exception":false,"start_time":"2024-02-19T03:21:23.5007","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.751531Z","iopub.execute_input":"2024-02-19T17:20:40.752158Z","iopub.status.idle":"2024-02-19T17:20:40.897144Z","shell.execute_reply.started":"2024-02-19T17:20:40.75209Z","shell.execute_reply":"2024-02-19T17:20:40.896146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target Distribution with Gender\n\npd.set_option('display.float_format', '{:.2f}'.format)\ntmp = pd.DataFrame(train.groupby([TARGET,'Gender'])[\"id\"].agg('count'))\ntmp.columns = ['Count']\ntrain[TARGET].value_counts()\ntmp = pd.merge(tmp,train[TARGET].value_counts(),left_index=True, right_index=True)\ntmp.columns = ['gender_count','target_class_count']\ntmp['%gender_count'] = tmp['gender_count']/tmp['target_class_count']\ntmp[\"%target_class_count\"] = tmp['target_class_count']/len(train) \ntmp = tmp[['gender_count','%gender_count','target_class_count','%target_class_count']]\nprint(\"Target Distribution with Gender\")\ntmp\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.060318,"end_time":"2024-02-19T03:21:23.72624","exception":false,"start_time":"2024-02-19T03:21:23.665922","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.898387Z","iopub.execute_input":"2024-02-19T17:20:40.898711Z","iopub.status.idle":"2024-02-19T17:20:40.940321Z","shell.execute_reply.started":"2024-02-19T17:20:40.898686Z","shell.execute_reply":"2024-02-19T17:20:40.939442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_num_cols = list(train.select_dtypes(\"float\").columns) \nraw_cat_cols = list(train.columns.drop(raw_num_cols+[TARGET]))\n\nfull_form = dict({'FAVC' : \"Frequent consumption of high caloric food\",\n                  'FCVC' : \"Frequency of consumption of vegetables\",\n                  'NCP' :\"Number of main meal\",\n                  'CAEC': \"Consumption of food between meals\",\n                  'CH2O': \"Consumption of water daily\",\n                  'SCC':  \"Calories consumption monitoring\",\n                  'FAF': \"Physical activity frequency\",\n                  'TUE': \"Time using technology devices\",\n                  'CALC': \"Consumption of alcohol\" ,\n                  'MTRANS' : \"Transportation used\"})\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.02623,"end_time":"2024-02-19T03:21:23.769405","exception":false,"start_time":"2024-02-19T03:21:23.743175","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.943716Z","iopub.execute_input":"2024-02-19T17:20:40.944Z","iopub.status.idle":"2024-02-19T17:20:40.951107Z","shell.execute_reply.started":"2024-02-19T17:20:40.943976Z","shell.execute_reply":"2024-02-19T17:20:40.950036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From Above Table, We Can See**\n* All the People in `Obesity_Type_II` are **Male** and in `Obesity_Type_III` all are **Female**\n* `Overweight_Level_II` consists `70%` **Male**, and `Insufficient_Weight` consists more than `60%` **Female**\n* From these point we can say that `Gender` is a important feature for the Obesity Prediction","metadata":{"papermill":{"duration":0.016048,"end_time":"2024-02-19T03:21:23.801869","exception":false,"start_time":"2024-02-19T03:21:23.785821","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Data Visualization\n\nThis section will delve into various aspects of data visualization. Below are the topics covered:\n\n## Individual Numerical Plots\nExploring individual numerical data through visualization techniques.\n\n## Individual Categorical Plots\nExamining individual categorical data using visualization methods.\n\n## Numerical Correlation Plot\nVisualizing the correlation between numerical variables to understand their relationships.\n\n## Combined Numerical Plots\nCreating combined numerical plots to gain insights into multiple variables simultaneously.","metadata":{"papermill":{"duration":0.015956,"end_time":"2024-02-19T03:21:23.834233","exception":false,"start_time":"2024-02-19T03:21:23.818277","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Target Distribution with Gender\n","metadata":{"papermill":{"duration":0.016435,"end_time":"2024-02-19T03:21:23.867158","exception":false,"start_time":"2024-02-19T03:21:23.850723","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, axs = plt.subplots(1,2,figsize = (12,5))\nplt.suptitle(\"Target Distribution\")\n\nsns.histplot(binwidth=0.5,x=TARGET,data=train,hue='Gender',palette=\"dark\",ax=axs[0],discrete=True)\naxs[0].tick_params(axis='x', rotation=60)\n\naxs[1].pie(\n        train[TARGET].value_counts(),\n        shadow = True,\n        explode=[.1 for i in range(train[TARGET].nunique())],\n        labels = train[TARGET].value_counts().index,\n        autopct='%1.f%%',\n    )\n\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":0.578201,"end_time":"2024-02-19T03:21:24.505267","exception":false,"start_time":"2024-02-19T03:21:23.927066","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:40.952385Z","iopub.execute_input":"2024-02-19T17:20:40.952747Z","iopub.status.idle":"2024-02-19T17:20:41.57021Z","shell.execute_reply.started":"2024-02-19T17:20:40.952721Z","shell.execute_reply":"2024-02-19T17:20:41.569261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"section_1\"> </a>\n# Individual Numerical Plots","metadata":{"execution":{"iopub.execute_input":"2024-02-06T08:06:50.621405Z","iopub.status.busy":"2024-02-06T08:06:50.620976Z","iopub.status.idle":"2024-02-06T08:06:50.629708Z","shell.execute_reply":"2024-02-06T08:06:50.627713Z","shell.execute_reply.started":"2024-02-06T08:06:50.621376Z"},"papermill":{"duration":0.017275,"end_time":"2024-02-19T03:21:24.540548","exception":false,"start_time":"2024-02-19T03:21:24.523273","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig,axs = plt.subplots(len(raw_num_cols),1,figsize=(12,len(raw_num_cols)*2.5),sharex=False)\nfor i, col in enumerate(raw_num_cols):\n    sns.violinplot(x=TARGET, y=col,hue=\"Gender\", data=train,ax = axs[i], split=False)\n    if col in full_form.keys():\n        axs[i].set_ylabel(full_form[col])\n\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":5.245549,"end_time":"2024-02-19T03:21:29.803547","exception":false,"start_time":"2024-02-19T03:21:24.557998","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-19T17:20:41.571338Z","iopub.execute_input":"2024-02-19T17:20:41.571659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Insights from above plots:\n* We should Ignore, **Female** distribution in `Obesity_Type_II` Class & **Male** distribution in \"Obesity_Type_III\". because of very small sample size\n* We can see People in category of `Insufficient Weight` consumes higher `Number of main Meal` maybe because to gain weight\n* `Frequency of consumption of Vegetables` is **Three** for everyone in class `Obesity Type III`\n* `Weight`, `Height` & `Gender` looks like the most important features. `Weight` shows very clear differentiation for diff classes","metadata":{"papermill":{"duration":0.024196,"end_time":"2024-02-19T03:21:29.852441","exception":false,"start_time":"2024-02-19T03:21:29.828245","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id = \"section_2\"> </a>\n# Individual Categorical Plots","metadata":{"papermill":{"duration":0.025121,"end_time":"2024-02-19T03:21:29.903026","exception":false,"start_time":"2024-02-19T03:21:29.877905","status":"completed"},"tags":[]}},{"cell_type":"code","source":"_,axs = plt.subplots(int(len(raw_cat_cols)-1),2,figsize=(12,len(raw_cat_cols)*3),width_ratios=[1, 4])\nfor i,col in enumerate(raw_cat_cols[1:]):\n    sns.countplot(y=col,data=train,palette=\"bright\",ax=axs[i,0])\n    sns.countplot(x=col,data=train,hue=TARGET,palette=\"bright\",ax=axs[i,1])\n    if col in full_form.keys():\n        axs[i,0].set_ylabel(full_form[col])\n\n\nplt.tight_layout()\nplt.show()\n","metadata":{"papermill":{"duration":3.683627,"end_time":"2024-02-19T03:21:33.610847","exception":false,"start_time":"2024-02-19T03:21:29.92722","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"section_3\"></a>\n# Numerical Correlation Plot","metadata":{"papermill":{"duration":0.028261,"end_time":"2024-02-19T03:21:33.667719","exception":false,"start_time":"2024-02-19T03:21:33.639458","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tmp = train[raw_num_cols].corr(\"pearson\")\nsns.heatmap(tmp,annot=True,cmap =\"crest\")","metadata":{"papermill":{"duration":0.777643,"end_time":"2024-02-19T03:21:34.473876","exception":false,"start_time":"2024-02-19T03:21:33.696233","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* `Height` has a positive corr with `Weight`,`FAF`. we will see there combined plots\n* People with higher `Weight` drinks more water.\n","metadata":{"papermill":{"duration":0.029627,"end_time":"2024-02-19T03:21:34.533223","exception":false,"start_time":"2024-02-19T03:21:34.503596","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id = \"section_4\"></a>\n# Combined Numerical Plots ","metadata":{"papermill":{"duration":0.029569,"end_time":"2024-02-19T03:21:34.592848","exception":false,"start_time":"2024-02-19T03:21:34.563279","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sns.jointplot(data=train, x=\"Height\", y=\"Weight\", hue=TARGET,height=6)","metadata":{"papermill":{"duration":3.3641,"end_time":"2024-02-19T03:21:37.986096","exception":false,"start_time":"2024-02-19T03:21:34.621996","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(data=train, x=\"Age\", y=\"Height\", hue=TARGET,height=6)","metadata":{"papermill":{"duration":3.340772,"end_time":"2024-02-19T03:21:41.368183","exception":false,"start_time":"2024-02-19T03:21:38.027411","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Principal Component Analysis (PCA) & KMeans\nThese plots are inspired by [This](https://www.kaggle.com/competitions/playground-series-s4e2/discussion/472471) discussion.","metadata":{"papermill":{"duration":0.036336,"end_time":"2024-02-19T03:21:41.441273","exception":false,"start_time":"2024-02-19T03:21:41.404937","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\n#PCA\npca = PCA(n_components=2)\npca_top_2 = pca.fit_transform(train[raw_num_cols])\n\ntmp = pd.DataFrame(data = pca_top_2, columns = ['pca_1','pca_2'])\ntmp['TARGET'] = train[TARGET]\n\nfig,axs = plt.subplots(2,1,figsize = (12,6))\nsns.scatterplot(data=tmp, y=\"pca_1\", x=\"pca_2\", hue='TARGET',ax=axs[0])\naxs[0].set_title(\"Top 2 Principal Components\")\n\n#KMeans\nkmeans = KMeans(7,random_state=RANDOM_SEED)\nkmeans.fit(tmp[['pca_1','pca_2']])\nsns.scatterplot( y= tmp['pca_1'],x = tmp['pca_2'],c = kmeans.labels_,cmap='viridis', marker='o', edgecolor='k', s=50, alpha=0.8,ax = axs[1])\naxs[1].set_title(\"Kmean Clustring on First 2 Principal Components\")\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":3.926146,"end_time":"2024-02-19T03:21:45.402581","exception":false,"start_time":"2024-02-19T03:21:41.476435","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering & Processing","metadata":{"papermill":{"duration":0.044943,"end_time":"2024-02-19T03:21:45.493119","exception":false,"start_time":"2024-02-19T03:21:45.448176","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# In age_rounder, height_rounder func we multiply values\n# by some value this sometimes improve model CV score\n# In Extract features we combine features to get new features\n\ndef age_rounder(x):\n    x_copy = x.copy()\n    x_copy['Age'] = (x_copy['Age']*100).astype(np.uint16)\n    return x_copy\n\ndef height_rounder(x):\n    x_copy = x.copy()\n    x_copy['Height'] = (x_copy['Height']*100).astype(np.uint16)\n    return x_copy\n\ndef extract_features(x):\n    x_copy = x.copy()\n    x_copy['BMI'] = (x_copy['Weight']/x_copy['Height']**2)\n#     x_copy['PseudoTarget'] = pd.cut(x_copy['BMI'],bins = [0,18.4,24.9,29,34.9,39.9,100],labels = [0,1,2,3,4,5],)    \n    return x_copy\n\ndef col_rounder(x):\n    x_copy = x.copy()\n    cols_to_round = ['FCVC',\"NCP\",\"CH2O\",\"FAF\",\"TUE\"]\n    for col in cols_to_round:\n        x_copy[col] = round(x_copy[col])\n        x_copy[col] = x_copy[col].astype('int')\n    return x_copy\n\nAgeRounder = FunctionTransformer(age_rounder)\nHeightRounder = FunctionTransformer(height_rounder)\nExtractFeatures = FunctionTransformer(extract_features)\nColumnRounder = FunctionTransformer(col_rounder)","metadata":{"papermill":{"duration":0.05658,"end_time":"2024-02-19T03:21:45.593826","exception":false,"start_time":"2024-02-19T03:21:45.537246","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using FeatureDropper we can drop columns. This is \n# important if we want to pass different set of features\n# for different models\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nclass FeatureDropper(BaseEstimator, TransformerMixin):\n    def __init__(self, cols):\n        self.cols = cols\n    def fit(self,x,y):\n        return self\n    def transform(self, x):\n        return x.drop(self.cols, axis = 1)","metadata":{"papermill":{"duration":0.053655,"end_time":"2024-02-19T03:21:45.692077","exception":false,"start_time":"2024-02-19T03:21:45.638422","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Next we will define `cross_val_model` which will be used to train and validate all the models we will use in this Notebook\n`cross_val_model` function gives three things: **val_scores**, **valid_predictions**, **test_predictions**\n* <b>val_scores:</b> This gives us accuracy score on Validation Data.\n* <b>valid_predictions:</b> This is a array which stores model predictions on validation set\n* <b>test_predictions:</b> This gives test prediction averaged by number of splits we are using","metadata":{"papermill":{"duration":0.041869,"end_time":"2024-02-19T03:21:45.774844","exception":false,"start_time":"2024-02-19T03:21:45.732975","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# In cross_val_model we cross vaidate models using\n# Stratified K-Fold.\n\n# Encoding target values with int\ntarget_mapping = {\n                  'Insufficient_Weight':0,\n                  'Normal_Weight':1,\n                  'Overweight_Level_I':2,\n                  'Overweight_Level_II':3, \n                  'Obesity_Type_I':4,\n                  'Obesity_Type_II':5 ,\n                  'Obesity_Type_III':6\n                  }\n\n# Define a method for Cross validation here we are using StartifiedKFold\nskf = StratifiedKFold(n_splits=n_splits)\n\ndef cross_val_model(estimators,cv = skf, verbose = True):\n    '''\n        estimators : pipeline consists preprocessing, encoder & model\n        cv : Method for cross validation (default: StratifiedKfold)\n        verbose : print train/valid score (yes/no)\n    '''\n    \n    X = train.copy()\n    y = X.pop(TARGET)\n\n    y = y.map(target_mapping)\n    test_predictions = np.zeros((len(test),7))\n    valid_predictions = np.zeros((len(X),7))\n\n    val_scores, train_scores = [],[]\n    for fold, (train_ind, valid_ind) in enumerate(skf.split(X,y)):\n        model = clone(estimators)\n        #define train set\n        X_train = X.iloc[train_ind]\n        y_train = y.iloc[train_ind]\n        #define valid set\n        X_valid = X.iloc[valid_ind]\n        y_valid = y.iloc[valid_ind]\n\n        model.fit(X_train, y_train)\n        if verbose:\n            print(\"-\" * 100)\n            print(f\"Fold: {fold}\")\n            print(f\"Train Accuracy Score:-{accuracy_score(y_true=y_train,y_pred=model.predict(X_train))}\")\n            print(f\"Valid Accuracy Score:-{accuracy_score(y_true=y_valid,y_pred=model.predict(X_valid))}\")\n            print(\"-\" * 100)\n\n        \n        test_predictions += model.predict_proba(test)/cv.get_n_splits()\n        valid_predictions[valid_ind] = model.predict_proba(X_valid)\n        val_scores.append(accuracy_score(y_true=y_valid,y_pred=model.predict(X_valid)))\n    if verbose: \n        print(f\"Average Mean Accuracy Score:- {np.array(val_scores).mean()}\")\n    return val_scores, valid_predictions, test_predictions","metadata":{"papermill":{"duration":0.055124,"end_time":"2024-02-19T03:21:45.872836","exception":false,"start_time":"2024-02-19T03:21:45.817712","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Combine Orignal & Synthetic Data\n\ntrain.drop(['id'],axis = 1, inplace = True)\ntest_ids = test['id']\ntest.drop(['id'],axis = 1, inplace=True)\n\ntrain = pd.concat([train,train_org],axis = 0)\ntrain = train.drop_duplicates()\ntrain.reset_index(drop=True, inplace=True)","metadata":{"papermill":{"duration":0.084198,"end_time":"2024-02-19T03:21:45.998489","exception":false,"start_time":"2024-02-19T03:21:45.914291","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# empty dataframe to store score, & train / test predictions.\nscore_list, oof_list, predict_list = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()","metadata":{"papermill":{"duration":0.050516,"end_time":"2024-02-19T03:21:46.090282","exception":false,"start_time":"2024-02-19T03:21:46.039766","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.040972,"end_time":"2024-02-19T03:21:46.171389","exception":false,"start_time":"2024-02-19T03:21:46.130417","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div style = \"font-size:120%\">Rather than focusing on a single model, in this competition it's better to combine predictions from many high performing models. In this notebook we will be training Four different type of models and will combine their predictions for final sub.</div>\n\n* [Random Forest Model](#rfc)\n* [LGBM Model](#lgbm)\n* [XGB Model](#xgb)\n* [Catboost Model](#cat)\n","metadata":{"papermill":{"duration":0.040207,"end_time":"2024-02-19T03:21:46.25276","exception":false,"start_time":"2024-02-19T03:21:46.212553","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id = \"rfC\"> </a>\n# Random Forest Model","metadata":{"papermill":{"duration":0.040498,"end_time":"2024-02-19T03:21:46.333668","exception":false,"start_time":"2024-02-19T03:21:46.29317","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define Random Forest Model Pipeline\n\nRFC = make_pipeline(\n                        ExtractFeatures,\n                        MEstimateEncoder(cols=['Gender','family_history_with_overweight','FAVC','CAEC',\n                                           'SMOKE','SCC','CALC','MTRANS']),\n                       RandomForestClassifier(random_state=RANDOM_SEED)\n                    )","metadata":{"papermill":{"duration":0.049049,"end_time":"2024-02-19T03:21:46.423531","exception":false,"start_time":"2024-02-19T03:21:46.374482","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Execute Random Forest Pipeline\nval_scores,val_predictions,test_predictions = cross_val_model(RFC)\n\n# Save train/test predictions in dataframes\nfor k,v in target_mapping.items():\n    oof_list[f\"rfc_{k}\"] = val_predictions[:,v]\n\nfor k,v in target_mapping.items():\n    predict_list[f\"rfc_{k}\"] = test_predictions[:,v]\n# 0.8975337326149792\n# 0.9049682643904575","metadata":{"papermill":{"duration":36.806233,"end_time":"2024-02-19T03:22:23.270693","exception":false,"start_time":"2024-02-19T03:21:46.46446","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"lgbm\"></a>\n# LGBM Model","metadata":{"papermill":{"duration":0.041678,"end_time":"2024-02-19T03:22:23.354712","exception":false,"start_time":"2024-02-19T03:22:23.313034","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define Optuna Function To Tune LGBM Model\n\ndef lgbm_objective(trial):\n    params = {\n        'learning_rate' : trial.suggest_float('learning_rate', .001, .1, log = True),\n        'max_depth' : trial.suggest_int('max_depth', 2, 20),\n        'subsample' : trial.suggest_float('subsample', .5, 1),\n        'min_child_weight' : trial.suggest_float('min_child_weight', .1, 15, log = True),\n        'reg_lambda' : trial.suggest_float('reg_lambda', .1, 20, log = True),\n        'reg_alpha' : trial.suggest_float('reg_alpha', .1, 10, log = True),\n        'n_estimators' : 1000,\n        'random_state' : RANDOM_SEED,\n        'device_type' : \"gpu\",\n        'num_leaves': trial.suggest_int('num_leaves', 10, 1000),\n\n        #'boosting_type' : 'dart',\n    }\n    \n    optuna_model = make_pipeline(\n                                 ExtractFeatures,\n                                 MEstimateEncoder(cols=['Gender','family_history_with_overweight','FAVC','CAEC',\n                                           'SMOKE','SCC','CALC','MTRANS']),\n                                LGBMClassifier(**params,verbose=-1)\n                                )\n    val_scores, _, _ = cross_val_model(optuna_model,verbose = False)\n    return np.array(val_scores).mean()\n\nlgbm_study = optuna.create_study(direction = 'maximize',study_name=\"LGBM\")","metadata":{"papermill":{"duration":0.05508,"end_time":"2024-02-19T03:22:23.452126","exception":false,"start_time":"2024-02-19T03:22:23.397046","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Execute LGBM Tuning, To Tune set `TUNE` to True (it will take a long time)\nTUNE = False\n\nwarnings.filterwarnings(\"ignore\")\nif TUNE:\n    lgbm_study.optimize(lgbm_objective, 50)\n","metadata":{"papermill":{"duration":0.04938,"end_time":"2024-02-19T03:22:23.543237","exception":false,"start_time":"2024-02-19T03:22:23.493857","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_columns = train.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_columns = train.select_dtypes(include=['object']).columns.tolist()\ncategorical_columns.remove('NObeyesdad')","metadata":{"papermill":{"duration":0.056295,"end_time":"2024-02-19T03:22:23.641158","exception":false,"start_time":"2024-02-19T03:22:23.584863","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"font-size:120%\">LGBM parameters in next cell are taken from @moazeldsokyx notebook you may check his great work in this notebook:<br></div>\n\nhttps://www.kaggle.com/code/moazeldsokyx/pgs4e2-highest-score-lgbm-hyperparameter-tuning/notebook\n","metadata":{"papermill":{"duration":0.0438,"end_time":"2024-02-19T03:22:23.727066","exception":false,"start_time":"2024-02-19T03:22:23.683266","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Here we defined LGBM Pipeline\n# Where we use One_Hot_Encoder, for categorical encoding\n# standard scaler for numerical column scaling\n\n\nparams = {'learning_rate': 0.04325905707439143, 'max_depth': 4, \n          'subsample': 0.6115083405793659, 'min_child_weight': 0.43633356137010687, \n          'reg_lambda': 9.231766981717822, 'reg_alpha': 1.875987414096491, 'num_leaves': 373,\n          'n_estimators' : 1000,'random_state' : RANDOM_SEED, 'device_type' : \"gpu\",\n         }\n\nbest_params = {\n    \"objective\": \"multiclass\",          # Objective function for the model\n    \"metric\": \"multi_logloss\",          # Evaluation metric\n    \"verbosity\": -1,                    # Verbosity level (-1 for silent)\n    \"boosting_type\": \"gbdt\",            # Gradient boosting type\n    \"random_state\": 42,       # Random state for reproducibility\n    \"num_class\": 7,                     # Number of classes in the dataset\n    'learning_rate': 0.030962211546832760,  # Learning rate for gradient boosting\n    'n_estimators': 500,                # Number of boosting iterations\n    'lambda_l1': 0.009667446568254372,  # L1 regularization term\n    'lambda_l2': 0.04018641437301800,   # L2 regularization term\n    'max_depth': 10,                    # Maximum depth of the trees\n    'colsample_bytree': 0.40977129346872643,  # Fraction of features to consider for each tree\n    'subsample': 0.9535797422450176,    # Fraction of samples to consider for each boosting iteration\n    'min_child_samples': 26             # Minimum number of data needed in a leaf\n}\n\nlgbm = make_pipeline(    \n                        ColumnTransformer(\n                        transformers=[('num', StandardScaler(), numerical_columns),\n                                  ('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns)]),\n                        LGBMClassifier(**best_params,verbose=-1)\n                    )","metadata":{"papermill":{"duration":0.053116,"end_time":"2024-02-19T03:22:23.822037","exception":false,"start_time":"2024-02-19T03:22:23.768921","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train LGBM Model\n\nval_scores,val_predictions,test_predictions = cross_val_model(lgbm)\n\nfor k,v in target_mapping.items():\n    oof_list[f\"lgbm_{k}\"] = val_predictions[:,v]\n    \nfor k,v in target_mapping.items():\n    predict_list[f\"lgbm_{k}\"] = test_predictions[:,v]\n\n#0.91420543252078","metadata":{"papermill":{"duration":153.708725,"end_time":"2024-02-19T03:24:57.572934","exception":false,"start_time":"2024-02-19T03:22:23.864209","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"xgb\"></a>\n# XGB Model","metadata":{"papermill":{"duration":0.043416,"end_time":"2024-02-19T03:24:57.6605","exception":false,"start_time":"2024-02-19T03:24:57.617084","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Optuna study for XGB Model\ndef xgb_objective(trial):\n    params = {\n        'grow_policy': trial.suggest_categorical('grow_policy', [\"depthwise\", \"lossguide\"]),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n        'gamma' : trial.suggest_float('gamma', 1e-9, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 0, 24),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 30),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n    }\n\n    params['booster'] = 'gbtree'\n    params['objective'] = 'multi:softmax'\n    params[\"device\"] = \"cuda\"\n    params[\"verbosity\"] = 0\n    params['tree_method'] = \"gpu_hist\"\n    \n    \n    optuna_model = make_pipeline(\n#                     ExtractFeatures,\n                    MEstimateEncoder(cols=['Gender','family_history_with_overweight','FAVC','CAEC',\n                                           'SMOKE','SCC','CALC','MTRANS']),\n                    XGBClassifier(**params,seed=RANDOM_SEED)\n                   )\n    \n    val_scores, _, _ = cross_val_model(optuna_model,verbose = False)\n    return np.array(val_scores).mean()\n\nxgb_study = optuna.create_study(direction = 'maximize')\n","metadata":{"papermill":{"duration":0.056958,"end_time":"2024-02-19T03:24:57.761239","exception":false,"start_time":"2024-02-19T03:24:57.704281","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tune using Optuna\nTUNE = False\nif TUNE:\n    xgb_study.optimize(xgb_objective, 50)","metadata":{"papermill":{"duration":0.051084,"end_time":"2024-02-19T03:24:57.857135","exception":false,"start_time":"2024-02-19T03:24:57.806051","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGB Pipeline\n\nparams = {\n    'n_estimators': 1312,\n    'learning_rate': 0.018279520260162645,\n    'gamma': 0.0024196354156454324,\n    'reg_alpha': 0.9025931173755949,\n    'reg_lambda': 0.06835667255875388,\n    'max_depth': 5,\n    'min_child_weight': 5,\n    'subsample': 0.883274050086088,\n    'colsample_bytree': 0.6579828557036317\n}\n# {'eta': 0.018387615982905264, 'max_depth': 29, 'subsample': 0.8149303101087905, 'colsample_bytree': 0.26750463604831476, 'min_child_weight': 0.5292380065098192, 'reg_lambda': 0.18952063379457604, 'reg_alpha': 0.7201451827004944}\n\nparams = {'grow_policy': 'depthwise', 'n_estimators': 690, \n               'learning_rate': 0.31829021594473056, 'gamma': 0.6061120644431842, \n               'subsample': 0.9032243794829076, 'colsample_bytree': 0.44474031945048287,\n               'max_depth': 10, 'min_child_weight': 22, 'reg_lambda': 4.42638097284094,\n               'reg_alpha': 5.927900973354344e-07,'seed':RANDOM_SEED}\n\nbest_params = {'grow_policy': 'depthwise', 'n_estimators': 982, \n               'learning_rate': 0.050053726931263504, 'gamma': 0.5354391952653927, \n               'subsample': 0.7060590452456204, 'colsample_bytree': 0.37939433412123275, \n               'max_depth': 23, 'min_child_weight': 21, 'reg_lambda': 9.150224029846654e-08,\n               'reg_alpha': 5.671063656994295e-08}\nbest_params['booster'] = 'gbtree'\nbest_params['objective'] = 'multi:softmax'\nbest_params[\"device\"] = \"cuda\"\nbest_params[\"verbosity\"] = 0\nbest_params['tree_method'] = \"gpu_hist\"\n    \nXGB = make_pipeline(\n#                     ExtractFeatures,\n#                     MEstimateEncoder(cols=['Gender','family_history_with_overweight','FAVC','CAEC',\n#                                            'SMOKE','SCC','CALC','MTRANS']),\n#                     FeatureDropper(['FAVC','FCVC']),\n#                     ColumnRounder,\n#                     ColumnTransformer(\n#                     transformers=[('num', StandardScaler(), numerical_columns),\n#                                   ('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns)]),\n                    MEstimateEncoder(cols=['Gender','family_history_with_overweight','FAVC','CAEC',\n                                           'SMOKE','SCC','CALC','MTRANS']),\n                    XGBClassifier(**best_params,seed=RANDOM_SEED)\n                   )","metadata":{"papermill":{"duration":0.056965,"end_time":"2024-02-19T03:24:57.970884","exception":false,"start_time":"2024-02-19T03:24:57.913919","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_scores,val_predictions,test_predictions = cross_val_model(XGB)\n\nfor k,v in target_mapping .items():\n    oof_list[f\"xgb_{k}\"] = val_predictions[:,v]\n\nfor k,v in target_mapping.items():\n    predict_list[f\"xgb_{k}\"] = test_predictions[:,v]\n    \n# 0.90634942296329\n#0.9117093455898445 with rounder\n#0.9163506382522121","metadata":{"papermill":{"duration":82.462982,"end_time":"2024-02-19T03:26:20.485787","exception":false,"start_time":"2024-02-19T03:24:58.022805","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"cat\"></a>\n# Catboost Model\n","metadata":{"papermill":{"duration":0.044433,"end_time":"2024-02-19T03:26:20.575975","exception":false,"start_time":"2024-02-19T03:26:20.531542","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Optuna Function For Catboost Model\ndef cat_objective(trial):\n    \n    params = {\n        \n        'iterations': 1000,  # High number of estimators\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'depth': trial.suggest_int('depth', 3, 10),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.01, 10.0),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n        'random_seed': RANDOM_SEED,\n        'verbose': False,\n        'task_type':\"GPU\"\n    }\n    \n    cat_features = ['Gender','family_history_with_overweight','FAVC','FCVC','NCP',\n                'CAEC','SMOKE','CH2O','SCC','FAF','TUE','CALC','MTRANS']\n    optuna_model = make_pipeline(\n                        ExtractFeatures,\n#                         AgeRounder,\n#                         HeightRounder,\n#                         MEstimateEncoder(cols = raw_cat_cols),\n                        CatBoostClassifier(**params,cat_features=cat_features)\n                        )\n    val_scores,_,_ = cross_val_model(optuna_model,verbose = False)\n    return np.array(val_scores).mean()\n    \ncat_study = optuna.create_study(direction = 'maximize')","metadata":{"papermill":{"duration":0.062878,"end_time":"2024-02-19T03:26:20.685859","exception":false,"start_time":"2024-02-19T03:26:20.622981","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'learning_rate': 0.13762007048684638, 'depth': 5, \n          'l2_leaf_reg': 5.285199432056192, 'bagging_temperature': 0.6029582154263095,\n         'random_seed': RANDOM_SEED,\n        'verbose': False,\n        'task_type':\"GPU\",\n         'iterations':1000}\n\n\nCB = make_pipeline(\n#                         ExtractFeatures,\n#                         AgeRounder,\n#                         HeightRounder,\n#                         MEstimateEncoder(cols = raw_cat_cols),\n#                         CatBoostEncoder(cols = cat_features),\n                        CatBoostClassifier(**params, cat_features=categorical_columns)\n                        )","metadata":{"papermill":{"duration":0.066417,"end_time":"2024-02-19T03:26:20.805012","exception":false,"start_time":"2024-02-19T03:26:20.738595","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Catboost Model\nval_scores,val_predictions,test_predictions = cross_val_model(CB)\nfor k,v in target_mapping.items():\n    oof_list[f\"cat_{k}\"] = val_predictions[:,v]\n\nfor k,v in target_mapping.items():\n    predict_list[f\"cat_{k}\"] = test_predictions[:,v]\n\n# best 0.91179835368868 with extract features, n_splits = 10\n# best 0.9121046227778054 without extract features, n_splits = 10","metadata":{"papermill":{"duration":102.85819,"end_time":"2024-02-19T03:28:03.715495","exception":false,"start_time":"2024-02-19T03:26:20.857305","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{"papermill":{"duration":0.045415,"end_time":"2024-02-19T03:28:03.807679","exception":false,"start_time":"2024-02-19T03:28:03.762264","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# skf = StratifiedKFold(n_splits=5)\nweights = {\"rfc_\":0,\n           \"lgbm_\":3,\n           \"xgb_\":1,\n           \"cat_\":0}\ntmp = oof_list.copy()\nfor k,v in target_mapping.items():\n    tmp[f\"{k}\"] = (weights['rfc_']*tmp[f\"rfc_{k}\"] +\n              weights['lgbm_']*tmp[f\"lgbm_{k}\"]+\n              weights['xgb_']*tmp[f\"xgb_{k}\"]+\n              weights['cat_']*tmp[f\"cat_{k}\"])    \ntmp['pred'] = tmp[target_mapping.keys()].idxmax(axis = 1)\ntmp['label'] = train[TARGET]\nprint(f\"Ensemble Accuracy Scoe: {accuracy_score(train[TARGET],tmp['pred'])}\")\n    \ncm = confusion_matrix(y_true = tmp['label'].map(target_mapping),\n                      y_pred = tmp['pred'].map(target_mapping),\n                     normalize='true')\n\ncm = cm.round(2)\nplt.figure(figsize=(8,8))\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                              display_labels = target_mapping.keys())\ndisp.plot(xticks_rotation=50)\nplt.tight_layout()\nplt.show()\n\n\"\"\"   BEST     \"\"\"\n\n# Best LB [0,1,0,0]\n# Average Train Score:0.9142044335854003\n# Average Valid Score:0.91420543252078\n\n# Best CV [1,3, 1,1]\n# Average Train Score:0.9168308163711971\n# Average Valid Score:0.9168308163711971\n# adding orignal data improves score","metadata":{"papermill":{"duration":0.473118,"end_time":"2024-02-19T03:28:04.326788","exception":false,"start_time":"2024-02-19T03:28:03.85367","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Submission","metadata":{"papermill":{"duration":0.047159,"end_time":"2024-02-19T03:28:04.421877","exception":false,"start_time":"2024-02-19T03:28:04.374718","status":"completed"},"tags":[]}},{"cell_type":"code","source":"weights","metadata":{"papermill":{"duration":0.057628,"end_time":"2024-02-19T03:28:04.526834","exception":false,"start_time":"2024-02-19T03:28:04.469206","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k,v in target_mapping.items():\n    predict_list[f\"{k}\"] = (weights['rfc_']*predict_list[f\"rfc_{k}\"]+\n                            weights['lgbm_']*predict_list[f\"lgbm_{k}\"]+\n                            weights['xgb_']*predict_list[f\"xgb_{k}\"]+\n                            weights['cat_']*predict_list[f\"cat_{k}\"])\n\nfinal_pred = predict_list[target_mapping.keys()].idxmax(axis = 1)\n\nsample_sub[TARGET] = final_pred\nsample_sub.to_csv(\"submission.csv\",index=False)\nsample_sub\n","metadata":{"papermill":{"duration":0.106008,"end_time":"2024-02-19T03:28:04.679827","exception":false,"start_time":"2024-02-19T03:28:04.573819","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feel free to fork and test different things. some of the things you may try:\n* Try Different weights and see how CV & LB changes. weights = {'rfc_': 0.0, 'lgbm_': 1.0, 'xgb_': 0.0, 'cat_': 0.0} gives best LB. you may try that first\n* In this Notebook we used `StandardScaler`, next we can try `Log & MinMax Scaler transformer`\n* Define new features in `extract_feature` function by combining different features\n* Tune the models again using Optuna\n* In this notebook we are using weighted average, next we may use a linear model to combine the predictions.\n\n**This notebook is inspired by the awesome work of Iqbal Syah Akbar. I highly recommend to check his work.**\n\nhttps://www.kaggle.com/code/iqbalsyahakbar/ps4e1-3rd-place-solution","metadata":{"papermill":{"duration":0.049943,"end_time":"2024-02-19T03:28:04.780512","exception":false,"start_time":"2024-02-19T03:28:04.730569","status":"completed"},"tags":[]}}]}